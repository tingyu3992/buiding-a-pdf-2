def main():
    query = "äººå·¥æ™ºæ…§åœ¨é†«ç™‚é ˜åŸŸæœ‰å“ªäº›æ‡‰ç”¨ï¼Ÿ"
    relevant_passages = [
        "äººå·¥æ™ºæ…§å¯å”åŠ©é†«å¸«åˆ†æå½±åƒæ•¸æ“šï¼Œä¾‹å¦‚æ”¾å°„ç·šå½±åƒè¨ºæ–·ã€‚",
        "AI æ¨¡å‹èƒ½å¾ç—…æ­·ä¸­é æ¸¬æ‚£è€…å¯èƒ½çš„å¥åº·é¢¨éšªï¼Œå¯¦ç¾æ—©æœŸé è­¦ã€‚",
        "èŠå¤©æ©Ÿå™¨äººæˆ–è™›æ“¬åŠ©æ‰‹å¯ç”¨æ–¼å›ç­”æ‚£è€…å¸¸è¦‹å•é¡Œï¼Œæå‡é†«ç™‚æ•ˆç‡ã€‚"
    ]

    final_prompt = make_rag_prompt(query, relevant_passages)

    # å›ºå®šæº«åº¦ç‚º 0.5
    temperature = 0.5
    token_limits = [20, 50, 200]

    print("=== å›æ‡‰é•·åº¦æ¸¬è©¦ï¼šmax_output_tokens ===")
    for max_tok in token_limits:
        print(f"\nğŸŸ¨ max_output_tokens = {max_tok}")
        answer = generate_answer(final_prompt, temperature=temperature, max_tokens=max_tok)
        print(answer)

    print("\n=== åˆ†æå»ºè­° ===")
    print("- max_tokens è¶Šå°ï¼Œè¼¸å‡ºè¶Šå®¹æ˜“è¢«æˆªæ–·ï¼Œèªæ„å¯èƒ½ä¸å®Œæ•´ã€‚")
    print("- max_tokens = 20 æ™‚ï¼Œé€šå¸¸åªæœ‰ä¸€å¥è©±æˆ–åŠå¥è©±ã€‚")
    print("- max_tokens = 50 å¯æä¾›ç°¡çŸ­æ‘˜è¦æˆ–è¦é»ã€‚")
    print("- max_tokens = 200 è¶³ä»¥ç”¢ç”Ÿè¼ƒå®Œæ•´æ®µè½ç”šè‡³å¤šæ®µã€‚")
